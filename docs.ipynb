{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook computes semantic similarity between TensorFlow and PyTorch API documentation using BERT embeddings.\n",
    "\n",
    "**Workflow:**\n",
    "1. Load API documentation from specified paths\n",
    "2. Preprocess text data\n",
    "3. Generate BERT embeddings\n",
    "4. Compute cross-framework similarity scores\n",
    "5. Identify and display most similar API pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers torch 'numpy<2' pandas\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import textwrap\n",
    "\n",
    "\n",
    "class APIVisitor(ast.NodeVisitor):\n",
    "    def __init__(self):\n",
    "        self.apis = []\n",
    "        self.current_class = None\n",
    "\n",
    "    def visit_FunctionDef(self, node):\n",
    "        if node.name.startswith(\"_\"):\n",
    "            return\n",
    "\n",
    "        func_doc = ast.get_docstring(node)\n",
    "\n",
    "        if func_doc is None:\n",
    "            return\n",
    "\n",
    "        prefix = self.current_class + \".\" if self.current_class else \"\"\n",
    "\n",
    "        self.apis.append(\n",
    "            {\n",
    "                \"name\": prefix + node.name,\n",
    "                \"doc\": func_doc.strip(),\n",
    "                \"type\": \"method\" if self.current_class else \"function\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.generic_visit(node)\n",
    "\n",
    "\n",
    "def extract_api_info(source_path):\n",
    "    with open(source_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            tree = ast.parse(f.read())\n",
    "        except SyntaxError:\n",
    "            return []\n",
    "\n",
    "    visitor = APIVisitor()\n",
    "    visitor.visit(tree)\n",
    "\n",
    "    return visitor.apis\n",
    "\n",
    "\n",
    "def scan_project(project_root, project_name):\n",
    "    all_apis = []\n",
    "\n",
    "    for root, _, files in os.walk(project_root):\n",
    "        for file in files:\n",
    "            if file.endswith(\".py\") and not file.startswith(\"_\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                rel_path = os.path.relpath(file_path, project_root)\n",
    "\n",
    "                module_path = rel_path.replace(\"/\", \".\").replace(\"\\\\\", \".\")[:-3]\n",
    "\n",
    "                for api in extract_api_info(file_path):\n",
    "                    full_name = (\n",
    "                        f\"{module_path}.{api['name']}\"\n",
    "                        if module_path != \".\"\n",
    "                        else api[\"name\"]\n",
    "                    )\n",
    "                    all_apis.append(\n",
    "                        {\n",
    "                            \"project\": project_name,\n",
    "                            \"name\": full_name,\n",
    "                            \"content\": textwrap.dedent(api[\"doc\"]).strip(),\n",
    "                            \"type\": api[\"type\"],\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "    return all_apis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7636 TensorFlow APIs\n",
      "Loaded 3685 PyTorch APIs\n"
     ]
    }
   ],
   "source": [
    "# Load documentation\n",
    "tf_docs = scan_project(\"data/tensorflow-2.17.0\", \"tensorflow\")\n",
    "torch_docs = scan_project(\"data/pytorch-2.4.0\", \"pytorch\")\n",
    "\n",
    "print(f\"Loaded {len(tf_docs)} TensorFlow APIs\")\n",
    "print(f\"Loaded {len(torch_docs)} PyTorch APIs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove code blocks\n",
    "    text = text.replace(\"```\", \"\")\n",
    "    # Collapse whitespace\n",
    "    text = \" \".join(text.split())\n",
    "    # Truncate to first 2000 characters to maintain context\n",
    "    return text[:2000]\n",
    "\n",
    "\n",
    "# Preprocess all documents\n",
    "for doc in tf_docs + torch_docs:\n",
    "    doc[\"processed_text\"] = preprocess_text(doc[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. BERT Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating BERT embeddings: 100%|██████████| 7636/7636 [00:28<00:00, 270.97it/s]\n",
      "Generating BERT embeddings: 100%|██████████| 3685/3685 [00:12<00:00, 303.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow embedding matrix shape: (7636, 768)\n",
      "PyTorch embedding matrix shape: (3685, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64 if device.type == \"cuda\" else 16\n",
    "\n",
    "# Initialize BERT model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "model.to(device)\n",
    "\n",
    "# Disable parallelism to avoid warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "def get_bert_embeddings(texts):\n",
    "    embeddings = []\n",
    "\n",
    "    with tqdm(total=len(texts), desc=\"Generating BERT embeddings\") as pbar:\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i : i + batch_size]\n",
    "            inputs = tokenizer(\n",
    "                batch,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            inputs.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "\n",
    "            # Use mean pooling of last hidden states\n",
    "            hidden_states = outputs.last_hidden_state.mean(dim=1)\n",
    "            batch_embeddings = hidden_states.to(\"cpu\").numpy()\n",
    "            embeddings.append(batch_embeddings)\n",
    "            pbar.update(len(batch))\n",
    "\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "\n",
    "# Generate embeddings for both frameworks\n",
    "tf_embeddings = get_bert_embeddings([doc[\"processed_text\"] for doc in tf_docs])\n",
    "torch_embeddings = get_bert_embeddings([doc[\"processed_text\"] for doc in torch_docs])\n",
    "\n",
    "print(f\"TensorFlow embedding matrix shape: {tf_embeddings.shape}\")\n",
    "print(f\"PyTorch embedding matrix shape: {torch_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cross-Framework Similarity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity matrix shape: (7636, 3685)\n"
     ]
    }
   ],
   "source": [
    "def compute_cross_similarity(matrix_a, matrix_b):\n",
    "    \"\"\"Compute pairwise cosine similarity between two embedding matrices\n",
    "\n",
    "    Args:\n",
    "        matrix_a (np.ndarray): N x D embedding matrix\n",
    "        matrix_b (np.ndarray): M x D embedding matrix\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: N x M similarity matrix\n",
    "    \"\"\"\n",
    "    # Normalize embeddings\n",
    "    matrix_a_norm = matrix_a / np.linalg.norm(matrix_a, axis=1, keepdims=True)\n",
    "    matrix_b_norm = matrix_b / np.linalg.norm(matrix_b, axis=1, keepdims=True)\n",
    "\n",
    "    return np.dot(matrix_a_norm, matrix_b_norm.T)\n",
    "\n",
    "\n",
    "# Compute similarity matrix\n",
    "similarity_matrix = compute_cross_similarity(tf_embeddings, torch_embeddings)\n",
    "print(f\"Similarity matrix shape: {similarity_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Identify Top Similar API Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_api</th>\n",
       "      <th>pytorch_api</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5761656</th>\n",
       "      <td>tensorflow.python.summary.writer.event_file_wr...</td>\n",
       "      <td>torch.utils.tensorboard.writer.flush</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27319916</th>\n",
       "      <td>tensorflow.python.data.ops.dataset_ops.is_subt...</td>\n",
       "      <td>torch.distributed.elastic.rendezvous.dynamic_r...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6772369</th>\n",
       "      <td>tensorflow.python.distribute.tpu_strategy.run</td>\n",
       "      <td>torch.distributed.elastic.rendezvous.dynamic_r...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27323652</th>\n",
       "      <td>tensorflow.python.data.ops.dataset_ops.most_sp...</td>\n",
       "      <td>torch.distributed.elastic.rendezvous.c10d_rend...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18954975</th>\n",
       "      <td>tensorflow.python.training.monitored_session.run</td>\n",
       "      <td>torch.distributed.elastic.rendezvous.dynamic_r...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826536</th>\n",
       "      <td>tensorflow.python.tpu.feature_column.shared_em...</td>\n",
       "      <td>torch.nn.functional.multi_head_attention_forward</td>\n",
       "      <td>0.951313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13932624</th>\n",
       "      <td>tensorflow.python.ops.numpy_ops.tests.np_test....</td>\n",
       "      <td>torch._dynamo.bytecode_transformation.encode_v...</td>\n",
       "      <td>0.951276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017822</th>\n",
       "      <td>tensorflow.python.framework.extension_type_tes...</td>\n",
       "      <td>torch._inductor.codegen.cpp.masked</td>\n",
       "      <td>0.951269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25281738</th>\n",
       "      <td>tensorflow.python.keras.engine.base_layer.add_...</td>\n",
       "      <td>torch.nn.modules.module.state_dict</td>\n",
       "      <td>0.951255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14766290</th>\n",
       "      <td>tensorflow.python.ops.ragged.ragged_math_ops.t...</td>\n",
       "      <td>torch.ao.quantization.pt2e.export_utils.forward</td>\n",
       "      <td>0.951240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tf_api  \\\n",
       "5761656   tensorflow.python.summary.writer.event_file_wr...   \n",
       "27319916  tensorflow.python.data.ops.dataset_ops.is_subt...   \n",
       "6772369       tensorflow.python.distribute.tpu_strategy.run   \n",
       "27323652  tensorflow.python.data.ops.dataset_ops.most_sp...   \n",
       "18954975   tensorflow.python.training.monitored_session.run   \n",
       "...                                                     ...   \n",
       "1826536   tensorflow.python.tpu.feature_column.shared_em...   \n",
       "13932624  tensorflow.python.ops.numpy_ops.tests.np_test....   \n",
       "4017822   tensorflow.python.framework.extension_type_tes...   \n",
       "25281738  tensorflow.python.keras.engine.base_layer.add_...   \n",
       "14766290  tensorflow.python.ops.ragged.ragged_math_ops.t...   \n",
       "\n",
       "                                                pytorch_api  similarity  \n",
       "5761656                torch.utils.tensorboard.writer.flush    1.000000  \n",
       "27319916  torch.distributed.elastic.rendezvous.dynamic_r...    1.000000  \n",
       "6772369   torch.distributed.elastic.rendezvous.dynamic_r...    1.000000  \n",
       "27323652  torch.distributed.elastic.rendezvous.c10d_rend...    1.000000  \n",
       "18954975  torch.distributed.elastic.rendezvous.dynamic_r...    1.000000  \n",
       "...                                                     ...         ...  \n",
       "1826536    torch.nn.functional.multi_head_attention_forward    0.951313  \n",
       "13932624  torch._dynamo.bytecode_transformation.encode_v...    0.951276  \n",
       "4017822                  torch._inductor.codegen.cpp.masked    0.951269  \n",
       "25281738                 torch.nn.modules.module.state_dict    0.951255  \n",
       "14766290    torch.ao.quantization.pt2e.export_utils.forward    0.951240  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_top_matches(sim_matrix, tf_docs, torch_docs):\n",
    "    matches = []\n",
    "    rows, cols = sim_matrix.shape\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            matches.append(\n",
    "                {\n",
    "                    \"tf_api\": tf_docs[i][\"name\"],\n",
    "                    \"tf_doc\": tf_docs[i][\"processed_text\"],\n",
    "                    \"pytorch_api\": torch_docs[j][\"name\"],\n",
    "                    \"pytorch_doc\": torch_docs[j][\"processed_text\"],\n",
    "                    \"similarity\": sim_matrix[i, j],\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(matches)\n",
    "    return (\n",
    "        df.sort_values(\"similarity\", ascending=False)\n",
    "        .drop_duplicates(subset=[\"tf_api\"], keep=\"first\")\n",
    "        .drop_duplicates(subset=[\"pytorch_api\"], keep=\"first\")\n",
    "        .head(500)\n",
    "    )\n",
    "\n",
    "\n",
    "# Get and display top matches\n",
    "top_matches = get_top_matches(similarity_matrix, tf_docs, torch_docs)\n",
    "\n",
    "with open(\"api_documentation_db.csv\", \"w\") as f:\n",
    "    top_matches.to_csv(f, index=False)\n",
    "\n",
    "top_matches[[\"tf_api\", \"pytorch_api\", \"similarity\"]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crossprobe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
