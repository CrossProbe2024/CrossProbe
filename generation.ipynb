{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrossProbe Code Transfer\n",
    "\n",
    "This notebook converts PyTorch/TensorFlow code based on the knowledge constructed in the *alignment* process.\n",
    "\n",
    "**Workflow:**\n",
    "1. Parse source code files\n",
    "2. Extract API calls with context\n",
    "3. Find matched APIs from documentation DB\n",
    "4. Generate target framework code with GPT-4o\n",
    "5. Save translated code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "%pip install openai\n",
    "\n",
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# Load previous documentation DB\n",
    "DOC_DB = pd.read_csv(\"api_documentation_db.csv\")\n",
    "\n",
    "# Set OpenAI API key from environment variables, or use a local Ollama server\n",
    "if api_key := os.getenv(\"OPENAI_API_KEY\"):\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "    model = \"gpt-4o\"\n",
    "else:\n",
    "    client = openai.OpenAI(\n",
    "        base_url=\"http://localhost:11434/v1\",\n",
    "        api_key=\"ollama\",\n",
    "    )\n",
    "    model = \"gemma3:27b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Code Analysis Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class APIExtractor(ast.NodeVisitor):\n",
    "    \"\"\"AST visitor for extracting framework API calls\"\"\"\n",
    "\n",
    "    def __init__(self, framework: str):\n",
    "        self.framework = framework\n",
    "        self.api_calls = []\n",
    "\n",
    "    def visit_Call(self, node):\n",
    "        if isinstance(node.func, ast.Attribute):\n",
    "            api_path = self._get_full_path(node.func)\n",
    "            if api_path.startswith(f\"{self.framework}.\"):\n",
    "                self.api_calls.append(api_path)\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def _get_full_path(self, node):\n",
    "        if isinstance(node.value, ast.Name):\n",
    "            return f\"{node.value.id}.{node.attr}\"\n",
    "        elif isinstance(node.value, ast.Attribute):\n",
    "            return f\"{self._get_full_path(node.value)}.{node.attr}\"\n",
    "        return node.attr\n",
    "\n",
    "\n",
    "def extract_apis(code: str, framework: str) -> List[str]:\n",
    "    \"\"\"Extract framework-specific API calls from code\"\"\"\n",
    "    tree = ast.parse(code)\n",
    "    extractor = APIExtractor(framework)\n",
    "    extractor.visit(tree)\n",
    "    return list(set(extractor.api_calls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Documentation Context Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(source_apis: List[str], target_framework: str) -> str:\n",
    "    \"\"\"Build prompt context from matched API documentation\"\"\"\n",
    "    context = []\n",
    "\n",
    "    for api in source_apis:\n",
    "        # Get source API docs\n",
    "        source_doc = DOC_DB.loc[api].to_dict() if api in DOC_DB.index else \"\"\n",
    "\n",
    "        # Find best matching target API\n",
    "        target_api = find_top_match(api, target_framework)\n",
    "        target_doc = DOC_DB.loc[target_api].to_dict() if target_api else \"\"\n",
    "\n",
    "        context.append(\n",
    "            f\"Source API ({'PyTorch' if 'torch' in api else 'TensorFlow'}): {api}\\n\"\n",
    "            f\"Documentation: {source_doc.get('processed_text', '')[:500]}\\n\\n\"\n",
    "            f\"Target API ({target_framework}): {target_api}\\n\"\n",
    "            f\"Documentation: {target_doc.get('processed_text', '')[:500]}\\n\"\n",
    "            \"----------------------------------------\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(context)\n",
    "\n",
    "\n",
    "def find_top_match(api: str, target_framework: str) -> str:\n",
    "    \"\"\"Find best matching API from previous similarity analysis\"\"\"\n",
    "    if \"torch\" in api:\n",
    "        return (\n",
    "            DOC_DB[(DOC_DB.framework == target_framework) & (DOC_DB.similar_api == api)]\n",
    "            .iloc[0]\n",
    "            .name\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            DOC_DB[(DOC_DB.framework == target_framework) & (DOC_DB.similar_api == api)]\n",
    "            .iloc[0]\n",
    "            .name\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GPT-4o Translation Engine\n",
    "You can replace the endpoint / model with other OpenAI-compatible API (e.g. ollama)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_code(code: str, source_framework: str, target_framework: str) -> str:\n",
    "    \"\"\"Translate code between frameworks using GPT-4o\"\"\"\n",
    "    apis = extract_apis(code, source_framework)\n",
    "    context = build_context(apis, target_framework)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"\n",
    "                You are an expert AI code translator specializing in {source_framework} to {target_framework} \n",
    "                conversions. Use the provided API documentation context to make accurate translations.\n",
    "                Maintain original functionality and code structure.\n",
    "            \"\"\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "                Documentation Context:\n",
    "                {context}\n",
    "\n",
    "                Source Code to Translate:\n",
    "                ```python\n",
    "                {code}\n",
    "                ```\n",
    "\n",
    "                Requirements:\n",
    "                1. Output only valid {target_framework} code\n",
    "                2. Preserve comments and code structure\n",
    "                3. Add conversion comments where non-trivial\n",
    "                4. Include necessary imports\n",
    "            \"\"\",\n",
    "            },\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=2000,\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "\n",
    "    if content.startswith(\"```python\") and content.endswith(\"```\"):\n",
    "        content = content[10:-3].strip()\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch Translation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transferring from PyTorch: 100%|██████████| 18/18 [03:18<00:00, 11.00s/it]\n",
      "Transferring from TensorFlow: 100%|██████████| 8/8 [02:12<00:00, 16.59s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def process_directory(source_dir: str, target_dir: str, source_framework: str):\n",
    "    \"\"\"Batch process directory for code translation\"\"\"\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    for root, _, files in os.walk(source_dir):\n",
    "        for file in tqdm(files, desc=\"Transferring from \" + source_framework):\n",
    "            if file.endswith(\".py\"):\n",
    "                source_path = os.path.join(root, file)\n",
    "                rel_path = os.path.relpath(source_path, source_dir)\n",
    "                target_path = os.path.join(target_dir, rel_path)\n",
    "\n",
    "                with open(source_path, \"r\") as f:\n",
    "                    code = f.read()\n",
    "\n",
    "                translated = translate_code(\n",
    "                    code,\n",
    "                    source_framework,\n",
    "                    \"TensorFlow\" if \"torch\" in source_framework else \"PyTorch\",\n",
    "                )\n",
    "\n",
    "                os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
    "                with open(target_path, \"w\") as f:\n",
    "                    f.write(translated)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "process_directory(\n",
    "    source_dir=\"pytorch\",\n",
    "    target_dir=\"tensorflow-test\",\n",
    "    source_framework=\"PyTorch\",\n",
    ")\n",
    "\n",
    "process_directory(\n",
    "    source_dir=\"tensorflow\",\n",
    "    target_dir=\"pytorch-test\",\n",
    "    source_framework=\"TensorFlow\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crossprobe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
